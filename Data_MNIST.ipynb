{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from quiver_engine.server import launch\n",
    "from keras.models import Model\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Input\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data load and preprocess\n",
    "- using 2,5,6,9\n",
    "## training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each number index\n",
    "idx_2 = np.where(y_train==2)[0]\n",
    "idx_5 = np.where(y_train==5)[0]\n",
    "idx_6 = np.where(y_train==6)[0]\n",
    "idx_9 = np.where(y_train==9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new data\n",
    "img_2 = X_train[idx_2]\n",
    "img_5 = X_train[idx_5]\n",
    "img_6 = X_train[idx_6]\n",
    "img_9 = X_train[idx_9]\n",
    "\n",
    "lab_2 = np.zeros((len(img_2), 4))\n",
    "lab_2[:,0] = 1.\n",
    "                 \n",
    "lab_5 = np.zeros((len(img_5), 4))\n",
    "lab_5[:,1] = 1.\n",
    "\n",
    "lab_6 = np.zeros((len(img_6), 4))\n",
    "lab_6[:,2] = 1.\n",
    "\n",
    "lab_9 = np.zeros((len(img_9), 4))\n",
    "lab_9[:,3] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize\n",
    "re_img2= np.zeros((len(idx_2),120,120))\n",
    "for i in range(0,len(idx_2)):\n",
    "    \n",
    "    img =img_2[i] \n",
    "    re_img2[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "re_img5= np.zeros((len(idx_5),120,120))\n",
    "for i in range(0,len(idx_5)):\n",
    "    img =img_5[i] \n",
    "    re_img5[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)             \n",
    "re_img6= np.zeros((len(idx_6),120,120))\n",
    "for i in range(0,len(idx_6)):\n",
    "    img =img_6[i] \n",
    "    re_img6[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "re_img9= np.zeros((len(idx_9),120,120))\n",
    "for i in range(0,len(idx_9)):\n",
    "    img =img_9[i] \n",
    "    re_img9[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make input data\n",
    "dnum = 30\n",
    "data_list = ['img2','img5','img6','img9' ]\n",
    "lab_list = ['lab2', 'lab5','lab6','lab9']\n",
    "\n",
    "data_dic = {'img2':re_img2[0:dnum], 'img5':re_img5[0:dnum],'img6':re_img6[0:dnum],'img9':re_img9[0:dnum]}\n",
    "lab_dic = {'lab2':lab_2[0:dnum],'lab5':lab_5[0:dnum],'lab6':lab_6[0:dnum],'lab9':lab_9[0:dnum]}\n",
    "\n",
    "new_x_train = np.zeros((dnum*4,120,120))\n",
    "new_y_train = np.zeros((dnum*4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    img = data_list[i]\n",
    "    lab= lab_list[i]\n",
    "    new_x_train[i*dnum:(i+1)*dnum] = data_dic[img]\n",
    "    new_y_train[i*dnum:(i+1)*dnum] = lab_dic[lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "color_x_train = np.zeros((len(new_x_train), 120,120,3))\n",
    "#expand dimension & GRAY to RGB\n",
    "for i in range(dnum*4):\n",
    "    tmp = np.expand_dims(new_x_train[i],axis=3)\n",
    "    color_x_train[i] = skimage.color.gray2rgb(new_x_train[i]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_x_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check \n",
    "i = 11900\n",
    "plt.imshow(color_x_train[i])\n",
    "plt.title('{}'.format(new_y_train[i]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:67: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "dnum_t = 100\n",
    "# save each number index\n",
    "idx_2t = np.where(y_test==2)[0]\n",
    "idx_5t = np.where(y_test==5)[0]\n",
    "idx_6t = np.where(y_test==6)[0]\n",
    "idx_9t = np.where(y_test==9)[0]\n",
    "\n",
    "# make new data\n",
    "img_2t = X_test[idx_2t]\n",
    "img_5t = X_test[idx_5t]\n",
    "img_6t = X_test[idx_6t]\n",
    "img_9t = X_test[idx_9t]\n",
    "\n",
    "lab_2t = np.zeros((len(img_2t), 4))\n",
    "lab_2t[:,0] = 1.\n",
    "                 \n",
    "lab_5t = np.zeros((len(img_5t), 4))\n",
    "lab_5t[:,1] = 1.\n",
    "\n",
    "lab_6t = np.zeros((len(img_6t), 4))\n",
    "lab_6t[:,2] = 1.\n",
    "\n",
    "lab_9t = np.zeros((len(img_9t), 4))\n",
    "lab_9t[:,3] = 1.\n",
    "\n",
    "\n",
    "# resize\n",
    "re_img2t= np.zeros((len(idx_2t),120,120))\n",
    "for i in range(0,len(idx_2t)):\n",
    "    \n",
    "    imgt =img_2t[i] \n",
    "    re_img2t[i] = cv2.resize(imgt,(120,120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "re_img5t= np.zeros((len(idx_5t),120,120))\n",
    "for i in range(0,len(idx_5t)):\n",
    "    imgt =img_5t[i] \n",
    "    re_img5t[i] = cv2.resize(imgt,(120,120), interpolation=cv2.INTER_AREA)             \n",
    "re_img6t= np.zeros((len(idx_6t),120,120))\n",
    "for i in range(0,len(idx_6t)):\n",
    "    imgt =img_6t[i] \n",
    "    re_img6t[i] = cv2.resize(imgt,(120,120), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "re_img9t= np.zeros((len(idx_9t),120,120))\n",
    "for i in range(0,len(idx_9t)):\n",
    "    imgt =img_9t[i] \n",
    "    re_img9t[i] = cv2.resize(imgt,(120,120), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "# make input data\n",
    "data_list_t = ['img2t','img5t','img6t','img9t' ]\n",
    "lab_list_t = ['lab2t', 'lab5t','lab6t','lab9t']\n",
    "\n",
    "data_dic_t = {'img2t':re_img2t[0:dnum_t], 'img5t':re_img5t[0:dnum_t],'img6t':re_img6t[0:dnum_t],'img9t':re_img9t[0:dnum_t]}\n",
    "lab_dic_t = {'lab2t':lab_2t[0:dnum_t],'lab5t':lab_5t[0:dnum_t],'lab6t':lab_6t[0:dnum_t],'lab9t':lab_9t[0:dnum_t]}\n",
    "\n",
    "new_x_test = np.zeros((dnum_t*4,120,120))\n",
    "new_y_test = np.zeros((dnum_t*4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    imgt = data_list_t[i]\n",
    "    labt= lab_list_t[i]\n",
    "    new_x_test[i*dnum_t:(i+1)*dnum_t] = data_dic_t[imgt]\n",
    "    new_y_test[i*dnum_t:(i+1)*dnum_t] = lab_dic_t[labt]\n",
    "    \n",
    "color_x_test = np.zeros((len(new_x_test), 120,120,3))\n",
    "#expand dimension & GRAY to RGB\n",
    "for i in range(dnum_t*4):\n",
    "    tmp = np.expand_dims(new_x_test[i],axis=3)\n",
    "    color_x_test[i] = skimage.color.gray2rgb(new_x_test[i]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(re_img6t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(color_x_test[399].astype(np.uint8))\n",
    "plt.figure()\n",
    "plt.imshow(color_x_test[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "- 기존 VGG16 모델에서 fully connected부분을 제외하고 가져옴\n",
    "- Flatten함수-> 추가하여 fully connected할 때 곱할 개수 구함\n",
    "- Dense 함수 -> shape이 (None, 512)인 layer 생성, classification layer(4) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(120,120,3))\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x) # fully connected할 때 곱할 값을 구함\n",
    "\n",
    "#x = Dense(2048, activation='relu', name='dense_1')(x)\n",
    "x = Dense(512, activation='relu', name='dense_2')(x)\n",
    "#predictions = Dense(5, activation='softmax', name='prediction')(x)\n",
    "predictions = Dense(4, activation='softmax', name='prediction')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle data and labels from different files in the same order\n",
    "idx = np.random.permutation(len(color_x_train))\n",
    "X_s,Y_s = color_x_train[idx], new_y_train[idx]\n",
    "#X_t,Y_t = color_x_test[idx], new_y_test[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss : categorical_crossentropy\n",
    "- optimizer : Adam(Learning Rate : 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.Adam(lr=0.0001),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 5.4817 - acc: 0.3426 - val_loss: 2.1140 - val_acc: 0.5833\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 1.9662 - acc: 0.6944 - val_loss: 0.3209 - val_acc: 0.9167\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.6960 - acc: 0.8981 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.4215 - acc: 0.9444 - val_loss: 0.0063 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.2182 - acc: 0.9630 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 0.0379 - acc: 0.9815 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 4.3517e-04 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 1.7464e-04 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 1.5382e-04 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 0s 1ms/step - loss: 1.8725e-04 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_s,Y_s,epochs=10,batch_size=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(color_x_test, new_y_test,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12638277358\n",
      "0.804999998212\n"
     ]
    }
   ],
   "source": [
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], 'r-')\n",
    "plt.plot(history.history['val_loss'], 'b-.')\n",
    "plt.legend(['loss', 'val_loss'], loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
