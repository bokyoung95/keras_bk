{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from quiver_engine.server import launch\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Input\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model생성\n",
    "- 기존 VGG16 모델에서 fully connected부분을 제외하고 가져옴\n",
    "- Flatten함수-> 추가하여 fully connected할 때 곱할 개수 구함\n",
    "- Dense 함수 -> shape이 (None, 512)인 layer 생성\n",
    "- Dense 함수 -> classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "#fully connected layer는 가져오지 않고 input shape 변환\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(120,120,3))\n",
    "x = base_model.output\n",
    "#x = Flatten(name='flatten')(x) # fully connected할 때 곱할 값을 구함\n",
    "#x = Dense(2048, activation='relu', name='dense_1')(x)\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', name='dense_1')(x)\n",
    "#x = Dense(512, activation='relu', name='dense_2')(x)\n",
    "predictions = Dense(2, activation='softmax', name='prediction')(x)\n",
    "#predictions = Dense(2, activation='softmax', name='prediction')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 120, 120, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 120, 120, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 120, 120, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 30, 30, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 15,245,125\n",
      "Trainable params: 530,437\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "#X_train = np.load('cd_img.npy')/255.0\n",
    "#Y_train = np.load('cd_label.npy')\n",
    "X_train = np.load('gender_img.npy')\n",
    "Y_train = np.load('gender_lab.npy')\n",
    "X_train.astype('float32')\n",
    "X_train=X_train/255\n",
    "X_train.astype('float32')\n",
    "\n",
    "print(X_train.dtype)\n",
    "print(Y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "- loss : categorical_crossentropy\n",
    "- optimizer : Adam(Learning Rate : 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "#keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.Adam(lr=0.0001), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 36 samples\n",
      "Epoch 1/200\n",
      "144/144 [==============================] - 2s 15ms/step - loss: 0.6770 - acc: 0.6181 - val_loss: 0.6374 - val_acc: 0.7778\n",
      "Epoch 2/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.6593 - acc: 0.6875 - val_loss: 0.6350 - val_acc: 0.7500\n",
      "Epoch 3/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.6397 - acc: 0.8333 - val_loss: 0.6526 - val_acc: 0.6944\n",
      "Epoch 4/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.6234 - acc: 0.8611 - val_loss: 0.6462 - val_acc: 0.7222\n",
      "Epoch 5/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.6052 - acc: 0.9028 - val_loss: 0.5883 - val_acc: 0.8333\n",
      "Epoch 6/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5901 - acc: 0.8681 - val_loss: 0.5563 - val_acc: 0.8889\n",
      "Epoch 7/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5749 - acc: 0.8819 - val_loss: 0.5555 - val_acc: 0.8889\n",
      "Epoch 8/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5600 - acc: 0.9097 - val_loss: 0.5776 - val_acc: 0.8056\n",
      "Epoch 9/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5475 - acc: 0.9167 - val_loss: 0.5926 - val_acc: 0.8056\n",
      "Epoch 10/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5343 - acc: 0.9236 - val_loss: 0.5758 - val_acc: 0.8056\n",
      "Epoch 11/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5213 - acc: 0.9236 - val_loss: 0.5402 - val_acc: 0.8333\n",
      "Epoch 12/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.5079 - acc: 0.9167 - val_loss: 0.5028 - val_acc: 0.8889\n",
      "Epoch 13/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4973 - acc: 0.9236 - val_loss: 0.4709 - val_acc: 0.8889\n",
      "Epoch 14/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4871 - acc: 0.9236 - val_loss: 0.4642 - val_acc: 0.8889\n",
      "Epoch 15/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4756 - acc: 0.9236 - val_loss: 0.4779 - val_acc: 0.8889\n",
      "Epoch 16/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4639 - acc: 0.9236 - val_loss: 0.5078 - val_acc: 0.8333\n",
      "Epoch 17/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4541 - acc: 0.9444 - val_loss: 0.5193 - val_acc: 0.8333\n",
      "Epoch 18/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4449 - acc: 0.9444 - val_loss: 0.5031 - val_acc: 0.8333\n",
      "Epoch 19/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4359 - acc: 0.9444 - val_loss: 0.4740 - val_acc: 0.8611\n",
      "Epoch 20/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4250 - acc: 0.9514 - val_loss: 0.4600 - val_acc: 0.8889\n",
      "Epoch 21/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4173 - acc: 0.9583 - val_loss: 0.4489 - val_acc: 0.8889\n",
      "Epoch 22/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4074 - acc: 0.9583 - val_loss: 0.4579 - val_acc: 0.8889\n",
      "Epoch 23/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.4008 - acc: 0.9514 - val_loss: 0.4611 - val_acc: 0.8611\n",
      "Epoch 24/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3922 - acc: 0.9514 - val_loss: 0.4405 - val_acc: 0.8889\n",
      "Epoch 25/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3848 - acc: 0.9583 - val_loss: 0.4123 - val_acc: 0.8889\n",
      "Epoch 26/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3779 - acc: 0.9444 - val_loss: 0.3985 - val_acc: 0.8889\n",
      "Epoch 27/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3705 - acc: 0.9444 - val_loss: 0.4058 - val_acc: 0.8889\n",
      "Epoch 28/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3630 - acc: 0.9583 - val_loss: 0.4080 - val_acc: 0.8889\n",
      "Epoch 29/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3562 - acc: 0.9583 - val_loss: 0.4144 - val_acc: 0.8889\n",
      "Epoch 30/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3500 - acc: 0.9583 - val_loss: 0.4163 - val_acc: 0.8889\n",
      "Epoch 31/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3439 - acc: 0.9583 - val_loss: 0.4143 - val_acc: 0.8889\n",
      "Epoch 32/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3377 - acc: 0.9514 - val_loss: 0.4055 - val_acc: 0.8889\n",
      "Epoch 33/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3315 - acc: 0.9514 - val_loss: 0.3877 - val_acc: 0.8889\n",
      "Epoch 34/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3263 - acc: 0.9583 - val_loss: 0.3666 - val_acc: 0.8889\n",
      "Epoch 35/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3200 - acc: 0.9583 - val_loss: 0.3621 - val_acc: 0.8889\n",
      "Epoch 36/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3142 - acc: 0.9583 - val_loss: 0.3692 - val_acc: 0.8889\n",
      "Epoch 37/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3106 - acc: 0.9514 - val_loss: 0.3861 - val_acc: 0.8889\n",
      "Epoch 38/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.3042 - acc: 0.9514 - val_loss: 0.3747 - val_acc: 0.8889\n",
      "Epoch 39/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2989 - acc: 0.9583 - val_loss: 0.3602 - val_acc: 0.8889\n",
      "Epoch 40/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2936 - acc: 0.9583 - val_loss: 0.3485 - val_acc: 0.8889\n",
      "Epoch 41/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2889 - acc: 0.9653 - val_loss: 0.3377 - val_acc: 0.8889\n",
      "Epoch 42/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2841 - acc: 0.9653 - val_loss: 0.3354 - val_acc: 0.8889\n",
      "Epoch 43/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2795 - acc: 0.9653 - val_loss: 0.3420 - val_acc: 0.8889\n",
      "Epoch 44/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2748 - acc: 0.9653 - val_loss: 0.3390 - val_acc: 0.8889\n",
      "Epoch 45/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2704 - acc: 0.9653 - val_loss: 0.3363 - val_acc: 0.8889\n",
      "Epoch 46/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2660 - acc: 0.9653 - val_loss: 0.3282 - val_acc: 0.8889\n",
      "Epoch 47/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2618 - acc: 0.9653 - val_loss: 0.3189 - val_acc: 0.8889\n",
      "Epoch 48/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2577 - acc: 0.9653 - val_loss: 0.3146 - val_acc: 0.8889\n",
      "Epoch 49/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2536 - acc: 0.9653 - val_loss: 0.3140 - val_acc: 0.8889\n",
      "Epoch 50/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2497 - acc: 0.9653 - val_loss: 0.3145 - val_acc: 0.8889\n",
      "Epoch 51/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2458 - acc: 0.9653 - val_loss: 0.3107 - val_acc: 0.8889\n",
      "Epoch 52/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2421 - acc: 0.9653 - val_loss: 0.3076 - val_acc: 0.8889\n",
      "Epoch 53/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2386 - acc: 0.9653 - val_loss: 0.3085 - val_acc: 0.8889\n",
      "Epoch 54/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2352 - acc: 0.9653 - val_loss: 0.3002 - val_acc: 0.8889\n",
      "Epoch 55/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2313 - acc: 0.9653 - val_loss: 0.3000 - val_acc: 0.8889\n",
      "Epoch 56/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2278 - acc: 0.9653 - val_loss: 0.3033 - val_acc: 0.8889\n",
      "Epoch 57/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2248 - acc: 0.9722 - val_loss: 0.3049 - val_acc: 0.8889\n",
      "Epoch 58/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2214 - acc: 0.9722 - val_loss: 0.2952 - val_acc: 0.8889\n",
      "Epoch 59/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2181 - acc: 0.9653 - val_loss: 0.2784 - val_acc: 0.8889\n",
      "Epoch 60/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2148 - acc: 0.9653 - val_loss: 0.2706 - val_acc: 0.8889\n",
      "Epoch 61/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2122 - acc: 0.9653 - val_loss: 0.2699 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2085 - acc: 0.9653 - val_loss: 0.2809 - val_acc: 0.8889\n",
      "Epoch 63/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2054 - acc: 0.9722 - val_loss: 0.2899 - val_acc: 0.8889\n",
      "Epoch 64/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2030 - acc: 0.9792 - val_loss: 0.2945 - val_acc: 0.8889\n",
      "Epoch 65/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.2009 - acc: 0.9861 - val_loss: 0.2892 - val_acc: 0.8889\n",
      "Epoch 66/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1997 - acc: 0.9722 - val_loss: 0.2681 - val_acc: 0.8889\n",
      "Epoch 67/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1944 - acc: 0.9722 - val_loss: 0.2646 - val_acc: 0.8889\n",
      "Epoch 68/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1920 - acc: 0.9722 - val_loss: 0.2580 - val_acc: 0.8889\n",
      "Epoch 69/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1892 - acc: 0.9722 - val_loss: 0.2470 - val_acc: 0.8889\n",
      "Epoch 70/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1876 - acc: 0.9653 - val_loss: 0.2346 - val_acc: 0.8889\n",
      "Epoch 71/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1851 - acc: 0.9653 - val_loss: 0.2393 - val_acc: 0.8889\n",
      "Epoch 72/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1820 - acc: 0.9653 - val_loss: 0.2488 - val_acc: 0.8889\n",
      "Epoch 73/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1805 - acc: 0.9722 - val_loss: 0.2628 - val_acc: 0.8889\n",
      "Epoch 74/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1775 - acc: 0.9861 - val_loss: 0.2608 - val_acc: 0.8889\n",
      "Epoch 75/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1751 - acc: 0.9861 - val_loss: 0.2585 - val_acc: 0.8889\n",
      "Epoch 76/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1731 - acc: 0.9861 - val_loss: 0.2505 - val_acc: 0.8889\n",
      "Epoch 77/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1708 - acc: 0.9861 - val_loss: 0.2459 - val_acc: 0.8889\n",
      "Epoch 78/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1697 - acc: 0.9792 - val_loss: 0.2332 - val_acc: 0.8889\n",
      "Epoch 79/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1664 - acc: 0.9792 - val_loss: 0.2354 - val_acc: 0.8889\n",
      "Epoch 80/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1645 - acc: 0.9792 - val_loss: 0.2364 - val_acc: 0.8889\n",
      "Epoch 81/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1625 - acc: 0.9861 - val_loss: 0.2450 - val_acc: 0.8889\n",
      "Epoch 82/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1603 - acc: 0.9861 - val_loss: 0.2437 - val_acc: 0.8889\n",
      "Epoch 83/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1585 - acc: 0.9861 - val_loss: 0.2372 - val_acc: 0.8889\n",
      "Epoch 84/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1563 - acc: 0.9861 - val_loss: 0.2296 - val_acc: 0.8889\n",
      "Epoch 85/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1545 - acc: 0.9861 - val_loss: 0.2229 - val_acc: 0.8889\n",
      "Epoch 86/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1526 - acc: 0.9861 - val_loss: 0.2206 - val_acc: 0.8889\n",
      "Epoch 87/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1512 - acc: 0.9861 - val_loss: 0.2227 - val_acc: 0.8889\n",
      "Epoch 88/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1489 - acc: 0.9861 - val_loss: 0.2168 - val_acc: 0.8889\n",
      "Epoch 89/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1471 - acc: 0.9861 - val_loss: 0.2151 - val_acc: 0.8889\n",
      "Epoch 90/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1454 - acc: 0.9861 - val_loss: 0.2152 - val_acc: 0.8889\n",
      "Epoch 91/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1436 - acc: 0.9861 - val_loss: 0.2182 - val_acc: 0.8889\n",
      "Epoch 92/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1420 - acc: 0.9861 - val_loss: 0.2174 - val_acc: 0.8889\n",
      "Epoch 93/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1402 - acc: 0.9861 - val_loss: 0.2115 - val_acc: 0.8889\n",
      "Epoch 94/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1387 - acc: 0.9861 - val_loss: 0.2041 - val_acc: 0.8889\n",
      "Epoch 95/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1369 - acc: 0.9861 - val_loss: 0.2023 - val_acc: 0.8889\n",
      "Epoch 96/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1356 - acc: 0.9861 - val_loss: 0.2007 - val_acc: 0.8889\n",
      "Epoch 97/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1336 - acc: 0.9861 - val_loss: 0.2073 - val_acc: 0.8889\n",
      "Epoch 98/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1323 - acc: 0.9861 - val_loss: 0.2134 - val_acc: 0.8889\n",
      "Epoch 99/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1308 - acc: 0.9861 - val_loss: 0.2111 - val_acc: 0.8889\n",
      "Epoch 100/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1293 - acc: 0.9861 - val_loss: 0.2069 - val_acc: 0.8889\n",
      "Epoch 101/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1276 - acc: 0.9861 - val_loss: 0.1960 - val_acc: 0.8889\n",
      "Epoch 102/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1262 - acc: 0.9861 - val_loss: 0.1858 - val_acc: 0.9167\n",
      "Epoch 103/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1248 - acc: 0.9861 - val_loss: 0.1816 - val_acc: 0.9167\n",
      "Epoch 104/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1235 - acc: 0.9861 - val_loss: 0.1835 - val_acc: 0.9167\n",
      "Epoch 105/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1231 - acc: 0.9861 - val_loss: 0.1934 - val_acc: 0.8889\n",
      "Epoch 106/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1206 - acc: 0.9861 - val_loss: 0.1906 - val_acc: 0.8889\n",
      "Epoch 107/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1191 - acc: 0.9861 - val_loss: 0.1921 - val_acc: 0.8889\n",
      "Epoch 108/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1177 - acc: 0.9861 - val_loss: 0.1947 - val_acc: 0.8889\n",
      "Epoch 109/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1166 - acc: 0.9861 - val_loss: 0.1976 - val_acc: 0.8889\n",
      "Epoch 110/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1156 - acc: 0.9861 - val_loss: 0.1927 - val_acc: 0.8889\n",
      "Epoch 111/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1137 - acc: 0.9861 - val_loss: 0.1790 - val_acc: 0.9167\n",
      "Epoch 112/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1132 - acc: 0.9861 - val_loss: 0.1663 - val_acc: 0.9167\n",
      "Epoch 113/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1117 - acc: 0.9861 - val_loss: 0.1659 - val_acc: 0.9167\n",
      "Epoch 114/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1103 - acc: 0.9861 - val_loss: 0.1711 - val_acc: 0.9167\n",
      "Epoch 115/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1092 - acc: 0.9861 - val_loss: 0.1790 - val_acc: 0.8889\n",
      "Epoch 116/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1076 - acc: 0.9861 - val_loss: 0.1806 - val_acc: 0.8889\n",
      "Epoch 117/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1066 - acc: 0.9861 - val_loss: 0.1825 - val_acc: 0.8889\n",
      "Epoch 118/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1056 - acc: 0.9861 - val_loss: 0.1784 - val_acc: 0.8889\n",
      "Epoch 119/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1041 - acc: 0.9861 - val_loss: 0.1669 - val_acc: 0.9167\n",
      "Epoch 120/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9861 - val_loss: 0.1584 - val_acc: 0.9167\n",
      "Epoch 121/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1021 - acc: 0.9861 - val_loss: 0.1562 - val_acc: 0.9167\n",
      "Epoch 122/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9861 - val_loss: 0.1587 - val_acc: 0.9167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0997 - acc: 0.9861 - val_loss: 0.1617 - val_acc: 0.9167\n",
      "Epoch 124/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0987 - acc: 0.9861 - val_loss: 0.1655 - val_acc: 0.9167\n",
      "Epoch 125/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0975 - acc: 0.9861 - val_loss: 0.1648 - val_acc: 0.9167\n",
      "Epoch 126/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0964 - acc: 0.9861 - val_loss: 0.1616 - val_acc: 0.9167\n",
      "Epoch 127/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0953 - acc: 0.9861 - val_loss: 0.1591 - val_acc: 0.9167\n",
      "Epoch 128/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0942 - acc: 0.9861 - val_loss: 0.1573 - val_acc: 0.9167\n",
      "Epoch 129/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0933 - acc: 0.9861 - val_loss: 0.1563 - val_acc: 0.9167\n",
      "Epoch 130/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0922 - acc: 0.9861 - val_loss: 0.1587 - val_acc: 0.9167\n",
      "Epoch 131/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0913 - acc: 0.9861 - val_loss: 0.1581 - val_acc: 0.9167\n",
      "Epoch 132/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0903 - acc: 0.9861 - val_loss: 0.1585 - val_acc: 0.9167\n",
      "Epoch 133/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.9861 - val_loss: 0.1599 - val_acc: 0.9167\n",
      "Epoch 134/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0884 - acc: 0.9861 - val_loss: 0.1609 - val_acc: 0.9167\n",
      "Epoch 135/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0876 - acc: 0.9861 - val_loss: 0.1565 - val_acc: 0.9167\n",
      "Epoch 136/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0864 - acc: 0.9861 - val_loss: 0.1530 - val_acc: 0.9167\n",
      "Epoch 137/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0858 - acc: 0.9861 - val_loss: 0.1465 - val_acc: 0.9444\n",
      "Epoch 138/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0845 - acc: 0.9861 - val_loss: 0.1453 - val_acc: 0.9444\n",
      "Epoch 139/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0836 - acc: 0.9861 - val_loss: 0.1442 - val_acc: 0.9444\n",
      "Epoch 140/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0828 - acc: 0.9861 - val_loss: 0.1432 - val_acc: 0.9444\n",
      "Epoch 141/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0818 - acc: 0.9861 - val_loss: 0.1449 - val_acc: 0.9444\n",
      "Epoch 142/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0810 - acc: 0.9861 - val_loss: 0.1471 - val_acc: 0.9167\n",
      "Epoch 143/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0803 - acc: 0.9861 - val_loss: 0.1465 - val_acc: 0.9167\n",
      "Epoch 144/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0793 - acc: 0.9861 - val_loss: 0.1406 - val_acc: 0.9444\n",
      "Epoch 145/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0784 - acc: 0.9861 - val_loss: 0.1306 - val_acc: 0.9444\n",
      "Epoch 146/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0777 - acc: 0.9861 - val_loss: 0.1255 - val_acc: 0.9444\n",
      "Epoch 147/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0771 - acc: 0.9861 - val_loss: 0.1259 - val_acc: 0.9444\n",
      "Epoch 148/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0761 - acc: 0.9931 - val_loss: 0.1270 - val_acc: 0.9444\n",
      "Epoch 149/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0752 - acc: 0.9931 - val_loss: 0.1317 - val_acc: 0.9444\n",
      "Epoch 150/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0743 - acc: 0.9931 - val_loss: 0.1363 - val_acc: 0.9444\n",
      "Epoch 151/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0736 - acc: 0.9861 - val_loss: 0.1386 - val_acc: 0.9444\n",
      "Epoch 152/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0731 - acc: 0.9861 - val_loss: 0.1422 - val_acc: 0.9167\n",
      "Epoch 153/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0724 - acc: 0.9861 - val_loss: 0.1368 - val_acc: 0.9444\n",
      "Epoch 154/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0715 - acc: 0.9931 - val_loss: 0.1317 - val_acc: 0.9444\n",
      "Epoch 155/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0705 - acc: 0.9931 - val_loss: 0.1293 - val_acc: 0.9444\n",
      "Epoch 156/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0698 - acc: 0.9931 - val_loss: 0.1283 - val_acc: 0.9444\n",
      "Epoch 157/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0689 - acc: 0.9931 - val_loss: 0.1236 - val_acc: 0.9722\n",
      "Epoch 158/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0683 - acc: 0.9931 - val_loss: 0.1203 - val_acc: 0.9722\n",
      "Epoch 159/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0676 - acc: 0.9931 - val_loss: 0.1198 - val_acc: 0.9722\n",
      "Epoch 160/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0669 - acc: 0.9931 - val_loss: 0.1236 - val_acc: 0.9722\n",
      "Epoch 161/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0661 - acc: 0.9931 - val_loss: 0.1233 - val_acc: 0.9722\n",
      "Epoch 162/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0654 - acc: 0.9931 - val_loss: 0.1247 - val_acc: 0.9722\n",
      "Epoch 163/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0647 - acc: 0.9931 - val_loss: 0.1249 - val_acc: 0.9722\n",
      "Epoch 164/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0641 - acc: 0.9931 - val_loss: 0.1221 - val_acc: 0.9722\n",
      "Epoch 165/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0636 - acc: 0.9931 - val_loss: 0.1176 - val_acc: 0.9722\n",
      "Epoch 166/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0627 - acc: 0.9931 - val_loss: 0.1170 - val_acc: 0.9722\n",
      "Epoch 167/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0621 - acc: 0.9931 - val_loss: 0.1168 - val_acc: 0.9722\n",
      "Epoch 168/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0615 - acc: 0.9931 - val_loss: 0.1169 - val_acc: 0.9722\n",
      "Epoch 169/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0607 - acc: 0.9931 - val_loss: 0.1147 - val_acc: 0.9722\n",
      "Epoch 170/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0602 - acc: 0.9931 - val_loss: 0.1119 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0598 - acc: 1.0000 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0591 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0583 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0578 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0560 - acc: 1.0000 - val_loss: 0.1074 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0554 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0544 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0533 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 1.0000\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0528 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0523 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0514 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0507 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0496 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0492 - acc: 1.0000 - val_loss: 0.0930 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0484 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.0921 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0475 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0471 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0467 - acc: 1.0000 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0456 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,epochs=200,batch_size=90, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, Y_train,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0528680522823\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], 'r-')\n",
    "plt.plot(history.history['val_loss'], 'b-.')\n",
    "plt.legend(['loss', 'val_loss'], loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\",'w') as json_file :\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
