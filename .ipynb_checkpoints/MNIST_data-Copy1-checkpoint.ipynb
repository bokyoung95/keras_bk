{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from quiver_engine.server import launch\n",
    "from keras.models import Model\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Input\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data load and preprocessing\n",
    "- Training\n",
    "- using 2,5,6,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each number index\n",
    "idx_2 = np.where(y_train==2)[0]\n",
    "idx_5 = np.where(y_train==5)[0]\n",
    "idx_6 = np.where(y_train==6)[0]\n",
    "idx_9 = np.where(y_train==9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new data\n",
    "img_2 = X_train[idx_2]\n",
    "img_5 = X_train[idx_5]\n",
    "img_6 = X_train[idx_6]\n",
    "img_9 = X_train[idx_9]\n",
    "\n",
    "lab_2 = np.zeros((len(img_2), 4))\n",
    "lab_2[:,0] = 1.\n",
    "                 \n",
    "lab_5 = np.zeros((len(img_5), 4))\n",
    "lab_5[:,1] = 1.\n",
    "\n",
    "lab_6 = np.zeros((len(img_6), 4))\n",
    "lab_6[:,2] = 1.\n",
    "\n",
    "lab_9 = np.zeros((len(img_9), 4))\n",
    "lab_9[:,3] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize\n",
    "re_img2= np.zeros((len(idx_2),120,120))\n",
    "for i in range(0,len(idx_2)):\n",
    "    \n",
    "    img =img_2[i] \n",
    "    re_img2[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "re_img5= np.zeros((len(idx_5),120,120))\n",
    "for i in range(0,len(idx_5)):\n",
    "    img =img_5[i] \n",
    "    re_img5[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)             \n",
    "re_img6= np.zeros((len(idx_6),120,120))\n",
    "for i in range(0,len(idx_6)):\n",
    "    img =img_6[i] \n",
    "    re_img6[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "re_img9= np.zeros((len(idx_9),120,120))\n",
    "for i in range(0,len(idx_9)):\n",
    "    img =img_9[i] \n",
    "    re_img9[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make input data\n",
    "dnum = 30\n",
    "data_list = ['img2','img5','img6','img9' ]\n",
    "lab_list = ['lab2', 'lab5','lab6','lab9']\n",
    "\n",
    "data_dic = {'img2':re_img2[0:dnum], 'img5':re_img5[0:dnum],'img6':re_img6[0:dnum],'img9':re_img9[0:dnum]}\n",
    "lab_dic = {'lab2':lab_2[0:dnum],'lab5':lab_5[0:dnum],'lab6':lab_6[0:dnum],'lab9':lab_9[0:dnum]}\n",
    "\n",
    "new_x_train = np.zeros((dnum*4,120,120))\n",
    "new_y_train = np.zeros((dnum*4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    img = data_list[i]\n",
    "    lab= lab_list[i]\n",
    "    new_x_train[i*dnum:(i+1)*dnum] = data_dic[img]\n",
    "    new_y_train[i*dnum:(i+1)*dnum] = lab_dic[lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "color_x_train = np.zeros((len(new_x_train), 120,120,3))\n",
    "#expand dimension\n",
    "for i in range(dnum*4):\n",
    "    tmp = np.expand_dims(new_x_train[i],axis=3)\n",
    "    color_x_train[i] = skimage.color.gray2rgb(new_x_train[i]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_x_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check \n",
    "i = 89\n",
    "plt.imshow(color_x_train[i])\n",
    "plt.title('{}'.format(new_y_train[i]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each number index\n",
    "idx_2 = np.where(y_train==2)[0]\n",
    "idx_5 = np.where(y_train==5)[0]\n",
    "idx_6 = np.where(y_train==6)[0]\n",
    "idx_9 = np.where(y_train==9)[0]\n",
    "\n",
    "# make new data\n",
    "img_2 = X_train[idx_2]\n",
    "img_5 = X_train[idx_5]\n",
    "img_6 = X_train[idx_6]\n",
    "img_9 = X_train[idx_9]\n",
    "\n",
    "lab_2 = np.zeros((len(img_2), 4))\n",
    "lab_2[:,0] = 1.\n",
    "                 \n",
    "lab_5 = np.zeros((len(img_5), 4))\n",
    "lab_5[:,1] = 1.\n",
    "\n",
    "lab_6 = np.zeros((len(img_6), 4))\n",
    "lab_6[:,2] = 1.\n",
    "\n",
    "lab_9 = np.zeros((len(img_9), 4))\n",
    "lab_9[:,3] = 1.\n",
    "\n",
    "\n",
    "# resize\n",
    "re_img2= np.zeros((len(idx_2),120,120))\n",
    "for i in range(0,len(idx_2)):\n",
    "    \n",
    "    img =img_2[i] \n",
    "    re_img2[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "re_img5= np.zeros((len(idx_5),120,120))\n",
    "for i in range(0,len(idx_5)):\n",
    "    img =img_5[i] \n",
    "    re_img5[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)             \n",
    "re_img6= np.zeros((len(idx_6),120,120))\n",
    "for i in range(0,len(idx_6)):\n",
    "    img =img_6[i] \n",
    "    re_img6[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "re_img9= np.zeros((len(idx_9),120,120))\n",
    "for i in range(0,len(idx_9)):\n",
    "    img =img_9[i] \n",
    "    re_img9[i] = cv2.resize(img,(120,120), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "# make input data\n",
    "dnum = 30\n",
    "data_list = ['img2','img5','img6','img9' ]\n",
    "lab_list = ['lab2', 'lab5','lab6','lab9']\n",
    "\n",
    "data_dic = {'img2':re_img2[0:dnum], 'img5':re_img5[0:dnum],'img6':re_img6[0:dnum],'img9':re_img9[0:dnum]}\n",
    "lab_dic = {'lab2':lab_2[0:dnum],'lab5':lab_5[0:dnum],'lab6':lab_6[0:dnum],'lab9':lab_9[0:dnum]}\n",
    "\n",
    "new_x_train = np.zeros((dnum*4,120,120))\n",
    "new_y_train = np.zeros((dnum*4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    img = data_list[i]\n",
    "    lab= lab_list[i]\n",
    "    new_x_train[i*dnum:(i+1)*dnum] = data_dic[img]\n",
    "    new_y_train[i*dnum:(i+1)*dnum] = lab_dic[lab]\n",
    "    \n",
    "color_x_train = np.zeros((len(new_x_train), 120,120,3))\n",
    "#expand dimension\n",
    "for i in range(dnum*4):\n",
    "    tmp = np.expand_dims(new_x_train[i],axis=3)\n",
    "    color_x_train[i] = skimage.color.gray2rgb(new_x_train[i]).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model생성\n",
    "- 기존 VGG16 모델에서 fully connected부분을 제외하고 가져옴\n",
    "- Flatten함수-> 추가하여 fully connected할 때 곱할 개수 구함\n",
    "- Dense 함수 -> shape이 (None, 512)인 layer 생성, classification layer(2&5) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(120,120,3))\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x) # fully connected할 때 곱할 값을 구함\n",
    "\n",
    "#x = Dense(2048, activation='relu', name='dense_1')(x)\n",
    "x = Dense(512, activation='relu', name='dense_2')(x)\n",
    "#predictions = Dense(5, activation='softmax', name='prediction')(x)\n",
    "predictions = Dense(4, activation='softmax', name='prediction')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle data and labels from different files in the same order\n",
    "idx = np.random.permutation(len(color_x_train))\n",
    "X_s,Y_s = color_x_train[idx], new_y_train[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss : categorical_crossentropy\n",
    "- optimizer : Adam(Learning Rate : 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.Adam(lr=0.0001),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 2s 18ms/step - loss: 7.7967 - acc: 0.2188 - val_loss: 4.5468 - val_acc: 0.4167\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.8192 - acc: 0.5937 - val_loss: 2.2895 - val_acc: 0.6250\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.2608 - acc: 0.7604 - val_loss: 2.3094 - val_acc: 0.7083\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.5937 - acc: 0.8958 - val_loss: 1.5613 - val_acc: 0.7083\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0587 - acc: 0.9687 - val_loss: 1.2818 - val_acc: 0.7083\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0224 - acc: 0.9896 - val_loss: 1.2384 - val_acc: 0.7500\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 1.2421 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.2332 - val_acc: 0.7917\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.2183 - val_acc: 0.7917\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.1988 - val_acc: 0.7917\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.1816 - val_acc: 0.8333\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 8.8394e-04 - acc: 1.0000 - val_loss: 1.1623 - val_acc: 0.8333\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 6.2326e-04 - acc: 1.0000 - val_loss: 1.1489 - val_acc: 0.7917\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.7399e-04 - acc: 1.0000 - val_loss: 1.1373 - val_acc: 0.7917\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.7488e-04 - acc: 1.0000 - val_loss: 1.1298 - val_acc: 0.7917\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.0202e-04 - acc: 1.0000 - val_loss: 1.1244 - val_acc: 0.7917\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.4109e-04 - acc: 1.0000 - val_loss: 1.1205 - val_acc: 0.7917\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1145e-04 - acc: 1.0000 - val_loss: 1.1180 - val_acc: 0.7917\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.8508e-04 - acc: 1.0000 - val_loss: 1.1158 - val_acc: 0.7917\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.6455e-04 - acc: 1.0000 - val_loss: 1.1138 - val_acc: 0.7917\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.5038e-04 - acc: 1.0000 - val_loss: 1.1119 - val_acc: 0.7917\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.3916e-04 - acc: 1.0000 - val_loss: 1.1105 - val_acc: 0.7917\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.2663e-04 - acc: 1.0000 - val_loss: 1.1093 - val_acc: 0.7917\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.1856e-04 - acc: 1.0000 - val_loss: 1.1078 - val_acc: 0.7917\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.1147e-04 - acc: 1.0000 - val_loss: 1.1066 - val_acc: 0.7917\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.0499e-04 - acc: 1.0000 - val_loss: 1.1074 - val_acc: 0.7917\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 9.6575e-05 - acc: 1.0000 - val_loss: 1.1076 - val_acc: 0.7917\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 9.1481e-05 - acc: 1.0000 - val_loss: 1.1077 - val_acc: 0.7917\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 8.6217e-05 - acc: 1.0000 - val_loss: 1.1076 - val_acc: 0.7917\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 8.2281e-05 - acc: 1.0000 - val_loss: 1.1073 - val_acc: 0.7917\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 7.8487e-05 - acc: 1.0000 - val_loss: 1.1069 - val_acc: 0.7917\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 7.5796e-05 - acc: 1.0000 - val_loss: 1.1065 - val_acc: 0.7917\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 7.3113e-05 - acc: 1.0000 - val_loss: 1.1062 - val_acc: 0.7917\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 7.0629e-05 - acc: 1.0000 - val_loss: 1.1057 - val_acc: 0.7917\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 6.8152e-05 - acc: 1.0000 - val_loss: 1.1050 - val_acc: 0.7917\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 6.6064e-05 - acc: 1.0000 - val_loss: 1.1036 - val_acc: 0.7917\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 6.4000e-05 - acc: 1.0000 - val_loss: 1.1026 - val_acc: 0.7917\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 6.1571e-05 - acc: 1.0000 - val_loss: 1.1016 - val_acc: 0.7917\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.9685e-05 - acc: 1.0000 - val_loss: 1.1008 - val_acc: 0.7917\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.8057e-05 - acc: 1.0000 - val_loss: 1.0999 - val_acc: 0.7917\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.6069e-05 - acc: 1.0000 - val_loss: 1.0988 - val_acc: 0.7917\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.3902e-05 - acc: 1.0000 - val_loss: 1.0977 - val_acc: 0.7917\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 5.2158e-05 - acc: 1.0000 - val_loss: 1.0978 - val_acc: 0.7917\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 5.0003e-05 - acc: 1.0000 - val_loss: 1.0975 - val_acc: 0.7917\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 4.8647e-05 - acc: 1.0000 - val_loss: 1.0974 - val_acc: 0.7917\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.6838e-05 - acc: 1.0000 - val_loss: 1.0971 - val_acc: 0.7917\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.5765e-05 - acc: 1.0000 - val_loss: 1.0971 - val_acc: 0.7917\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 4.4401e-05 - acc: 1.0000 - val_loss: 1.0968 - val_acc: 0.7917\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.3091e-05 - acc: 1.0000 - val_loss: 1.0962 - val_acc: 0.7917\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 4.2032e-05 - acc: 1.0000 - val_loss: 1.0955 - val_acc: 0.7917\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.1026e-05 - acc: 1.0000 - val_loss: 1.0950 - val_acc: 0.7917\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 4.0031e-05 - acc: 1.0000 - val_loss: 1.0946 - val_acc: 0.7917\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.8856e-05 - acc: 1.0000 - val_loss: 1.0940 - val_acc: 0.7917\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.7903e-05 - acc: 1.0000 - val_loss: 1.0932 - val_acc: 0.7917\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.6977e-05 - acc: 1.0000 - val_loss: 1.0927 - val_acc: 0.7917\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.6057e-05 - acc: 1.0000 - val_loss: 1.0923 - val_acc: 0.7917\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.5142e-05 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.7917\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.4274e-05 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.7917\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.3178e-05 - acc: 1.0000 - val_loss: 1.0914 - val_acc: 0.7917\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.2469e-05 - acc: 1.0000 - val_loss: 1.0920 - val_acc: 0.7917\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96/96 [==============================] - 0s 1ms/step - loss: 3.1590e-05 - acc: 1.0000 - val_loss: 1.0921 - val_acc: 0.7917\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 3.0917e-05 - acc: 1.0000 - val_loss: 1.0921 - val_acc: 0.7917\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 3.0064e-05 - acc: 1.0000 - val_loss: 1.0920 - val_acc: 0.7917\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.9496e-05 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.7917\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.8894e-05 - acc: 1.0000 - val_loss: 1.0917 - val_acc: 0.7917\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.8354e-05 - acc: 1.0000 - val_loss: 1.0916 - val_acc: 0.7917\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.7865e-05 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.7917\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.7336e-05 - acc: 1.0000 - val_loss: 1.0914 - val_acc: 0.7917\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.6877e-05 - acc: 1.0000 - val_loss: 1.0914 - val_acc: 0.7917\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.6305e-05 - acc: 1.0000 - val_loss: 1.0914 - val_acc: 0.7917\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.5608e-05 - acc: 1.0000 - val_loss: 1.0918 - val_acc: 0.7917\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.5002e-05 - acc: 1.0000 - val_loss: 1.0926 - val_acc: 0.7917\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.4581e-05 - acc: 1.0000 - val_loss: 1.0929 - val_acc: 0.7917\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.3972e-05 - acc: 1.0000 - val_loss: 1.0931 - val_acc: 0.7917\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.3436e-05 - acc: 1.0000 - val_loss: 1.0930 - val_acc: 0.7917\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.3047e-05 - acc: 1.0000 - val_loss: 1.0931 - val_acc: 0.7917\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.2684e-05 - acc: 1.0000 - val_loss: 1.0928 - val_acc: 0.7917\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.2278e-05 - acc: 1.0000 - val_loss: 1.0926 - val_acc: 0.7917\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.1931e-05 - acc: 1.0000 - val_loss: 1.0920 - val_acc: 0.7917\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.1585e-05 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.7917\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.1305e-05 - acc: 1.0000 - val_loss: 1.0912 - val_acc: 0.7917\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 2.0966e-05 - acc: 1.0000 - val_loss: 1.0907 - val_acc: 0.7917\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0610e-05 - acc: 1.0000 - val_loss: 1.0903 - val_acc: 0.7917\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0331e-05 - acc: 1.0000 - val_loss: 1.0900 - val_acc: 0.7917\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 2.0063e-05 - acc: 1.0000 - val_loss: 1.0898 - val_acc: 0.7917\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.9810e-05 - acc: 1.0000 - val_loss: 1.0897 - val_acc: 0.7917\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9540e-05 - acc: 1.0000 - val_loss: 1.0895 - val_acc: 0.7917\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.9311e-05 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.7917\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.9032e-05 - acc: 1.0000 - val_loss: 1.0890 - val_acc: 0.7917\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.8767e-05 - acc: 1.0000 - val_loss: 1.0888 - val_acc: 0.7917\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.8570e-05 - acc: 1.0000 - val_loss: 1.0886 - val_acc: 0.7917\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.8324e-05 - acc: 1.0000 - val_loss: 1.0885 - val_acc: 0.7917\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.8077e-05 - acc: 1.0000 - val_loss: 1.0884 - val_acc: 0.7917\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 1.7881e-05 - acc: 1.0000 - val_loss: 1.0882 - val_acc: 0.7917\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.7680e-05 - acc: 1.0000 - val_loss: 1.0880 - val_acc: 0.7917\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.7476e-05 - acc: 1.0000 - val_loss: 1.0879 - val_acc: 0.7917\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.7259e-05 - acc: 1.0000 - val_loss: 1.0878 - val_acc: 0.7917\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.7076e-05 - acc: 1.0000 - val_loss: 1.0876 - val_acc: 0.7917\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6868e-05 - acc: 1.0000 - val_loss: 1.0875 - val_acc: 0.7917\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 1.6669e-05 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.7917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_s,Y_s,epochs=100,batch_size=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_t, Y_t,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], 'r-')\n",
    "plt.plot(history.history['val_loss'], 'b-.')\n",
    "plt.legend(['loss', 'val_loss'], loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
