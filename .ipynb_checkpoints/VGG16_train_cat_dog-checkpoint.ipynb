{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from quiver_engine.server import launch\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Input\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model생성\n",
    "- 기존 VGG16 모델에서 fully connected부분을 제외하고 가져옴\n",
    "- Flatten함수-> 추가하여 fully connected할 때 곱할 개수 구함\n",
    "- Dense 함수 -> shape이 (None, 512)인 layer 생성, classification layer(2&5) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(120,120,3))\n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x) # fully connected할 때 곱할 값을 구함\n",
    "\n",
    "#x = Dense(2048, activation='relu', name='dense_1')(x)\n",
    "x = Dense(512, activation='relu', name='dense_2')(x)\n",
    "#predictions = Dense(5, activation='softmax', name='prediction')(x)\n",
    "predictions = Dense(2, activation='softmax', name='prediction')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "#X_train = np.load('cd_img.npy')/255.0\n",
    "#Y_train = np.load('cd_label.npy')\n",
    "X=np.zeros((60,120,120,3))\n",
    "Y=np.zeros((60,2))\n",
    "X_train = np.load('cd_img2.npy')/255.0\n",
    "X[0:30] = X_train[0:30]\n",
    "X[30:60] = X_train[12500:12530]\n",
    "Y_train = np.load('cd_label2.npy')\n",
    "Y[0:30] = Y_train[0:30]\n",
    "Y[30:60] = Y_train[12500:12530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "X_test=np.zeros((60,120,120,3))\n",
    "Y_test=np.zeros((60,2))\n",
    "X_test[0:30] = X_train[30:60]\n",
    "X_test[30:60] = X_train[12530:12560]\n",
    "Y_test[0:30] = Y_train[30:60]\n",
    "Y_test[30:60] = Y_train[12530:12560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle data and labels from different files in the same order\n",
    "idx = np.random.permutation(len(X))\n",
    "X_s,Y_s = X[idx], Y[idx]\n",
    "X_t,Y_t = X_test[idx], Y_test[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss : categorical_crossentropy\n",
    "- optimizer : Adam(Learning Rate : 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.Adam(lr=0.0001),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 6 samples\n",
      "Epoch 1/50\n",
      "54/54 [==============================] - 2s 30ms/step - loss: 0.7945 - acc: 0.4074 - val_loss: 0.5229 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.5955 - acc: 0.7037 - val_loss: 0.4101 - val_acc: 0.8333\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.4481 - acc: 0.8889 - val_loss: 0.3759 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.3382 - acc: 0.9630 - val_loss: 0.3763 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2785 - acc: 0.9815 - val_loss: 0.3473 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.2250 - acc: 0.9815 - val_loss: 0.2782 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1772 - acc: 1.0000 - val_loss: 0.2486 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1496 - acc: 1.0000 - val_loss: 0.2343 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1232 - acc: 1.0000 - val_loss: 0.2308 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.1021 - acc: 1.0000 - val_loss: 0.2440 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0879 - acc: 1.0000 - val_loss: 0.2547 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0761 - acc: 1.0000 - val_loss: 0.2473 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0634 - acc: 1.0000 - val_loss: 0.2204 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0536 - acc: 1.0000 - val_loss: 0.2023 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0483 - acc: 1.0000 - val_loss: 0.1939 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0432 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 1.0000\n",
      "Epoch 18/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0330 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 1.0000\n",
      "Epoch 21/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 1.0000\n",
      "Epoch 22/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.1856 - val_acc: 1.0000\n",
      "Epoch 23/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.1783 - val_acc: 1.0000\n",
      "Epoch 24/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1709 - val_acc: 1.0000\n",
      "Epoch 25/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 26/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.1588 - val_acc: 1.0000\n",
      "Epoch 27/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.1554 - val_acc: 1.0000\n",
      "Epoch 28/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1527 - val_acc: 1.0000\n",
      "Epoch 29/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 1.0000\n",
      "Epoch 30/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 1.0000\n",
      "Epoch 31/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 1.0000\n",
      "Epoch 32/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.1480 - val_acc: 1.0000\n",
      "Epoch 33/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1460 - val_acc: 1.0000\n",
      "Epoch 34/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1440 - val_acc: 1.0000\n",
      "Epoch 35/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1412 - val_acc: 1.0000\n",
      "Epoch 36/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 1.0000\n",
      "Epoch 37/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.1351 - val_acc: 1.0000\n",
      "Epoch 38/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 1.0000\n",
      "Epoch 39/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1303 - val_acc: 1.0000\n",
      "Epoch 40/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 41/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 1.0000\n",
      "Epoch 42/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.1244 - val_acc: 1.0000\n",
      "Epoch 43/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.1233 - val_acc: 1.0000\n",
      "Epoch 44/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 1.0000\n",
      "Epoch 45/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.1203 - val_acc: 1.0000\n",
      "Epoch 46/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.1187 - val_acc: 1.0000\n",
      "Epoch 47/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1174 - val_acc: 1.0000\n",
      "Epoch 48/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 49/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.1152 - val_acc: 1.0000\n",
      "Epoch 50/50\n",
      "54/54 [==============================] - 0s 1ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_s,Y_s,epochs=50,batch_size=30, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_t, Y_t,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438268661499\n",
      "0.84999999404\n"
     ]
    }
   ],
   "source": [
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], 'r-')\n",
    "plt.plot(history.history['val_loss'], 'b-.')\n",
    "plt.legend(['loss', 'val_loss'], loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
